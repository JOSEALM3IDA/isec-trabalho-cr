\documentclass[11pt]{article}
\usepackage{graphicx}
\usepackage[margin=2.5cm]{geometry}
\usepackage{tikz}
\usepackage{indentfirst}
\usepackage{tabularx}
\usepackage{listingsutf8}
\usepackage{color}
\usepackage{hyperref}
\usepackage[portuguese]{babel}

\graphicspath{{./images/}}

\def\checkmark{\tikz\fill[scale=0.4](0,.35) -- (.25,0) -- (1,.7) -- (.25,.15) -- cycle;} 
\setlength{\parskip}{0.5em}

\hypersetup{
	colorlinks=false,
	linktoc=all,
	hidelinks,
}

\lstset{
	belowcaptionskip=1\baselineskip,
	captionpos=b,
	frame=tb,
	language=C,
	aboveskip=3mm,
	belowskip=3mm,
	showstringspaces=false,
	columns=flexible,
	basicstyle={\small\ttfamily},
	numbers=none,
	numberstyle=\tiny\color{gray},
	keywordstyle=\color{blue},
	commentstyle=\color{dkgreen},
	stringstyle=\color{mauve},
	breaklines=true,
	breakatwhitespace=true,
	tabsize=3,
	inputencoding=utf8,
	extendedchars=true,
	literate={á}{{\'a}}1 {ã}{{\~a}}1 {à}{{\`a} }1 {Ã}{{\~A}}1 {ó}{{\'o}}1 {Ó}{{\'O}}1 {Í}{{\'I}}1 {í}{{\'i}}1 {é}{{\'e}}1 {ç}{{\c{c}}}1 {Ç}{{\c{C}}}1 {ú}{{\'u}}1
}

\begin{document}
	\include{Cover.tex}
	
	\tableofcontents
	\pagebreak
	
	\large
	\section{Introdução}
	
	\normalsize
	Este trabalho, feito no âmbito da Unidade Curricular de Conhecimento e Raciocínio, tem como objetivo o desenvolvimento e estudo estatístico de redes neuronais para identificação de alguns caracteres gregos. A linguagem e tecnologia usada para esse efeito é o MATLAB. Adicionalmente, o trabalho prático inclui uma aplicação gráfica que permite criar, treinar e simular redes.
	
	\large
	\section{Conversão e Tratamento das Imagens: Inputs e Targets}
	\normalsize
	
	O dataset usado no trabalho é constituído por 4 pastas. Destas 4, uma foi criada por nós, com 2 caracteres gregos de cada um dos 10 que devem ser identificáveis pelas redes. As outras 3 foram fornecidas junto com o enunciado, e não tiveram qualquer tratamento prévio fora do MATLAB.
	
	De modo a diminuir os custos de tempo e memória de treino, as imagens, ao serem lidas pelo programa, são redimensionadas para 28x28 (de 3024x3024). De seguida, são colocadas em matrizes binárias e convertidas em uma única coluna, pois, no MATLAB, as redes neuronais recebem os seus \textit{inputs} na forma de colunas de uma matriz.
	
	As imagens, no nosso trabalho, devem ser lidas por ordem alfabética, e em grupos de 10 caracteres diferentes, ou seja, todos os caracteres, para efeitos de treino, devem estar presentes em igual número e ordenados alfabeticamente.
	
	Relativamente ao tratamento dos \textit{targets} da rede neuronal, estes são criados usando matrizes de identidade 10 por 10. Cada coluna da matriz de targets terá 10 linhas, ou seja, uma para cada carater, preenchida com um valor que deve ser 0 ou 1: 1 caso a imagem correspondente contenha o carater que a linha representa, ou 0, em caso contrário.
	
	Analisando, no momento de produção deste relatório, o tratamento feito às imagens, concluímos que devíamos ter aplicado outras técnicas que teriam um impacto positivo no desempenho da rede, tal como fazer o \textit{trim} das imagens, ou seja, remover os espaços em branco à volta das mesmas, visando uniformizar os tamanhos dos caracteres fornecidos à rede.

	\pagebreak
	
	\large
	\section{Treino e Estudo Estatístico}
	\subsection{Pasta 1}
	\normalsize
	
	Iniciando-se então o processo de desenvolvimento e estudo da rede neuronal, foram testadas várias topologias, funções de ativação e de treino. Todos os valores obtidos foram colocados no excel em anexo.
	
	Comparado com a configuração base de uma camada escondida com 10 neurónios, notamos um impacto positivo, em geral, quando é aumentado o número de camadas escondidas, assim como o número de neurónios por camada, tendo este último um impacto mais significativo no desempenho da rede.
	
	Relativamente ao impacto da função de treino no desempenho da rede, observamos que, pelo menos nos nossos testes, nenhuma das outras funções de treino, neste caso, alcançaram melhores valores do que a configuração base. No entanto, grande parte das mesmas reduz muito a complexidade temporal necessária ao treino.
	
	Por fim, foram testadas várias configurações possíveis para funções de ativação. A partir destes testes, concluímos que usar a função de ativação \textbf{purelin} na camada de \textit{output} tem melhores resultados.
	
	No entanto, os testes efetuados na pasta 1 não são muito significativos, pois até mesmo a configuração base escolhida obtém valores ótimos de desempenho. Isto deve-se ao facto de que as redes, nestes testes, estão a ter acesso e a usar para treino todos os exemplos da pasta. Nesta pasta existe apenas um exemplo por carater grego possível, tornando-se impossível não usar 100\% das imagens para treino.
	
	\pagebreak
	
	
	\large
	\subsection{Pasta 2}
	\normalsize
	
	Nesta pasta, a matriz de targets deve ser invertida, pois as imagens encontram-se pela ordem inversa à alfabética, e poderia causar incompatibilidades com as outras pastas caso a mesma não fosse invertida.
	
	Testando, de forma semelhante à pasta 1, o impacto do número e dimensão das camadas escondidas, chegamos aos mesmos resultados: mais camadas e neurónios são benéficos para a rede, pelo menos até certo ponto. No entanto, o aumento do número de camadas e neurónios tem um elevado custo temporal e de memória associado, facto que foi tido em conta ao longo de todo o estudo estatístico.
	
	O mesmo aconteceu quanto ao estudo sobre o desempenho das várias funções de treino: nenhuma delas superou a \textbf{trainlm}, presente na configuração base.
	
	Foi testado, de igual forma, o impacto das funções de ativação no desempenho da rede. Obtivemos aqui uma das melhores redes, que reportou um desempenho de \textbf{1.8139E-29} (neste caso, quanto mais baixo melhor). No entanto, esta rede, cujas funções de ativação foram ambas configuradas com \textbf{purelin}, não obteve os melhores resultados em termos de desempenho de validação e de teste. Mesmo assim, decidimos guardá-la e testá-la um pouco mais, posteriormente.
	
	Devido ao maior tamanho do dataset disponível na pasta 2, já é possível, aqui, dividir os exemplos pelos três conjuntos (de treino, de validação e de teste). De um modo geral, quanto maior for o número de exemplos para treino disponível à rede, melhor o seu desempenho. No entanto, devem existir pelo menos alguns exemplos para validação e teste, pois estes permitem um melhor estudo estatístico das redes: tornam possível a avaliação da rede face a exemplos que não usou durante o treino. A existência de elementos nestes conjuntos permitem à rede autoavaliar-se e, se achar conveniente, terminar mais cedo o treino, o que faz com que a complexidade temporal de treino das redes seja mais reduzido, embora com alguns impactos no desempenho da mesma.
	
	Para finalizar o teste dos diferentes parâmetros da rede, fizemos variar a função de divisão dos conjuntos, onde notamos um melhor desempenho aquando do uso da função \textbf{divideblock}. Pensamos que isso se deva à forma como os nossos \textit{inputs} são lidos e fornecidos à rede, em blocos de 10 caracteres.
	
	Por fim, decidimos juntar os melhores parâmetros de cada teste, de modo a analisar se o melhoramento individual dos parâmetros tem um impacto positivo no desempenho da rede. Foi aqui que atingimos os melhores valores de desempenho até então vistos, tendo sidas destacadas 4 redes, com resultados bastante satifatórios em todos os indicadores que considerámos. Todas as 5 redes escolhidas partilham a mesma função de ativação \textbf{purelin} para a camada de \textit{output}, sendo que apenas 1 delas não utiliza a função de divisão \textbf{divideblock}.
	
	\pagebreak
	
	\large
	\subsection{Pasta 3}
	\normalsize
	
	Este dataset foi usado para testar as melhores redes obtidas até ao momento. Notamos que todas elas acertaram em, pelo menos, 70\% das imagens que compõem a pasta 3, tendo a rede 51 acertado quase na totalidade dos exemplos (95\%). Esta rede destaca-se também por ter conseguido avaliar corretamente todos os exemplos da pasta 2.
	
	De seguida, as respetivas parametrizações de cada rede foram usadas para criar novas redes treinadas apenas com o dataset da pasta 3. As redes foram avaliadas posteriormente com base no seu desempenho na avaliação das imagens das pastas 1, 2 e 3. Algumas destas redes não tiveram um bom desempenho, tendo uma das melhores redes até ao momento, a rede 29, resultados na fronteira do aleatório. No entanto, a superioridade da rede 51 manteve-se, nesta avaliação. Também a rede 47 teve bons resultados, igualando ou chegando perto dos resultados da rede 51.
	
	\large
	\subsection{Treino Geral}
	\normalsize
	
	As 5 melhores redes até ao momento - 29, 47, 48, 51 e 52 - foram treinadas do zero usando os exemplos das pastas 1, 2 e 3. Aqui, a rede 51 perde, por pouco, a sua superioridade, tendo a rede 52 conseguido resultados ligeiramente melhores na avaliação da pasta 3. Mesmo não tendo sido a melhor neste teste em específico, a rede 51 mostrou uma adaptação melhor a novas imagens (que não tinha usado durante o teste) e, portanto, consideramos que esta é a melhor rede obtida durante o estudo estatístico e desenvolvimento das redes neuronais feito. 
	
	Esta rede inclui apenas uma \textit{hidden layer} de 10 neurónios, tendo essa camada, assim como a camada de \textit{output}, sido configuradas com a função de ativação \textbf{purelin}, mostrando a superioridade da mesma, pelo menos neste caso.
	
	\large
	\section{Casos Extra - Pasta 4}
	\normalsize
	
	Para completar a avaliação das redes neuronais, foi usada a melhor rede obtida até ao momento na identificação de caracteres desenhados por nós, que estão presentes na pasta 4. A rede conseguiu identificar, com sucesso, 7 dos 20 caracteres fornecidos neste dataset. Concluímos que a rede não teve um melhor desempenho, nestes exemplos, pois parte deles não são similares em tamanho com os caracteres usados para fins de treino. Como já referido, isto poderia ser resolvido fazendo o \textit{trim} prévio das imagens, normalizando-se assim os tamanhos dos caracteres fornecidos à rede, permitindo um foco maior desta na forma de cada caracter e não no seu tamanho.
	
	\large
	\section{Interface Gráfica}
	\normalsize
	
	Como previamente referido, o trabalho inclui também uma interface gráfica, que permite criar, treinar, carregar e guardar redes neuronais, assim como simular esta com caracteres individuais ou até mesmo conjuntos de caracteres.
	
	Não conseguimos, no entanto, permitir o desenho e avaliação de caracteres desenhados diretamente nesta interface, algo que atribuímos a limitações do MATLAB.
	
	\large
	\section{Conclusão}
	\normalsize
	
	Observámos que a parametrização das redes é crucial no seu desempenho, sendo esta parametrização dependente do problema em questão. De alta importância é também o tratamento prévio das imagens, que permite à rede focar-se nas características que são mais relevantes ao problema - como, neste caso, a forma dos caracteres.
	
	Concluímos, então, este trabalho sobre redes neuronais, que consideramos ter sido um sucesso, tanto em termos de aprendizagem e aplicação de conceitos como em termos de desenvolvimento de redes neuronais com desempenhos aceitáveis.
	
	
	\large
	\section{Anexos}

	\normalsize
	\listoffigures
\end{document}